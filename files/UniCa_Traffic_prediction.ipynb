{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#UniCa - AI/ML for Networking 2026\n",
        "\n",
        "**Description:** This script provides some basic code to train a time series forecaster for traffic prediction. The dataset you are going to use contains data from multiple APs. In particular, each AP's dataset contains the following features:\n",
        "\n",
        "* `datetime` is the timestamp (date) at which the measurement was taken\n",
        "* `Bytes` is the number of Bytes contributed at the corresponding datetime\n",
        "* `Active Connections` is the number of active connections (users connected to the AP) at the corresponding datetime\n",
        "* `Active Users` is the number of active users at the corresponding datetime\n",
        "* `AP ID` is the ID of the AP where the measurement was taken\n",
        "\n",
        "Original dataset: Chen, W., Lyu, F., Wu, F., Yang, P., & Ren, J. (2021). Flag: Flexible, accurate, and long-time user load prediction in large-scale WiFi system using deep RNN. IEEE Internet of Things Journal, 8(22), 16510-16521.\n",
        "\n",
        "Contact: Francesc Wilhelmi (francisco.wilhelmi@upf.edu)"
      ],
      "metadata": {
        "id": "ShbB8CxBMSLH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up the environment"
      ],
      "metadata": {
        "id": "Lqio72iAuxNJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Connect your Google Drive"
      ],
      "metadata": {
        "id": "hfR6f_lHpklt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Nl_xYKv2oYRb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1f47fb4-a55b-4b63-fc16-3c0d7e9bcbe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Download the dataset"
      ],
      "metadata": {
        "id": "RQxCHlkswbru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/fwilhelmi/fwilhelmi.github.io/blob/master/files/datasetLab3.pkl"
      ],
      "metadata": {
        "id": "o6I9dNnpwbUB",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "240e9cb6-4f9d-4432-ed2f-c3bf7549b056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-04 16:41:14--  https://github.com/fwilhelmi/fwilhelmi.github.io/blob/master/files/datasetLab3.pkl\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘datasetLab3.pkl’\n",
            "\n",
            "datasetLab3.pkl         [ <=>                ] 179.36K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-06-04 16:41:15 (5.69 MB/s) - ‘datasetLab3.pkl’ saved [183666]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Define the main path of the code"
      ],
      "metadata": {
        "id": "-5ZtSumzuZCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mypath=\"drive/MyDrive/AAX/Lab3\""
      ],
      "metadata": {
        "id": "VYfdaJF-qr5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Extract the source code to the destination folder"
      ],
      "metadata": {
        "id": "ISnLhobTwh7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd $mypath"
      ],
      "metadata": {
        "id": "rgEgC4fZwiLf",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7026886c-183a-44f0-800f-e3b44c21b45a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AAX/Lab3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the data\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "97kVtaWOutFD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data from the pickle file (https://docs.python.org/3/library/pickle.html) that contains the dataset.\n",
        "\n",
        "**Important:** If you have issues with the dataset after automatically downloading and extracting it, download it and move it manually to the indicated folder."
      ],
      "metadata": {
        "id": "tZ-ATejy308z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "print(os.getcwd())\n",
        "print(os.path.exists('datasetLab3.pkl'))\n",
        "\n",
        "# Open and load the pickle file\n",
        "try:\n",
        "    with open('datasetLab3.pkl', 'rb') as f:\n",
        "        loaded_data = pickle.load(f)\n",
        "    print(\"Data loaded successfully:\")\n",
        "    print(loaded_data)\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'datasetLab3.pkl' not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "id": "Rn9zlRDcenHJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d77b2203-045a-45ef-b580-5c1c75e4ef26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AAX/Lab3\n",
            "True\n",
            "Data loaded successfully:\n",
            "                     Bytes  Active Connections  Active Users   AP ID\n",
            "datetime                                                            \n",
            "2019-04-30 07:10:00    0.0            0.075209           0.0  7-1012\n",
            "2019-04-30 07:20:00    0.0            0.000000           0.0  7-1012\n",
            "2019-04-30 07:30:00    0.0            0.000000           0.0  7-1012\n",
            "2019-04-30 07:40:00    0.0            0.000000           0.0  7-1012\n",
            "2019-04-30 07:50:00    0.0            0.000000           0.0  7-1012\n",
            "...                    ...                 ...           ...     ...\n",
            "2019-05-14 07:10:00    0.0            0.000000           0.0   7-104\n",
            "2019-05-14 07:20:00    0.0            0.000000           0.0   7-104\n",
            "2019-05-14 07:30:00    0.0            0.000000           0.0   7-104\n",
            "2019-05-14 07:40:00    0.0            0.000000           0.0   7-104\n",
            "2019-05-14 07:50:00    0.0            0.034091           0.0   7-104\n",
            "\n",
            "[211064 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(loaded_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4U_H2H5LjVn",
        "outputId": "320d8579-2bf9-484a-9036-eea841d81d74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EXERCISES"
      ],
      "metadata": {
        "id": "bTAXUX5lN9KF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 1:\n",
        "\n",
        "Analyze the data from the different APs and discuss their properites (stationarity, trends, seasonality).\n",
        "\n",
        "Select 2 or 3 key APs showing different properties and generate:\n",
        "\n",
        "* Line plots (to plot the load vs the time)\n",
        "* Autocorrelation plots (to show the relationship between past and future samples of the load)\n",
        "* An Augmented Dickey-Fuller test (to study the stationarity of the AP)\n",
        "\n"
      ],
      "metadata": {
        "id": "weqFFp6eShJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (response to exercise 1)"
      ],
      "metadata": {
        "id": "o3tirZCOSkNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2:\n",
        "\n",
        "Prepare the data to be presented as a time series to the ML model. For that, you will have to split features from samples by differentiating between an observation window (e.g., 10 samples) and a prediction window (e.g., 2 samples). Use a sliding window to iterate over all the samples.\n",
        "\n",
        "Example: For an array [0,1,2,3,4,5], using an observation window $T_o$ = 3 and a prediction window $T_p$ = 1 would lead to the following time series data:\n",
        "* $x_1$ = [0,1,2], $y_1$ = [3]\n",
        "* $x_2$ = [1,2,3], $x_2$ = [4]\n",
        "* $x_3$ = [2,3,4], $y_3$ = [5]\n",
        "\n",
        "(where x are the features and y the labels)"
      ],
      "metadata": {
        "id": "E3vAU830SmuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (response to exercise 2)"
      ],
      "metadata": {
        "id": "PTjjIcWDS3yC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 3:\n",
        "\n",
        "Split the time series data into train, test, and validation, based on your criteria."
      ],
      "metadata": {
        "id": "7hgfWEriSpMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (response to exercise 3)"
      ],
      "metadata": {
        "id": "PqgnnqflZ8R3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 4:\n",
        "Define a model (e.g., GRU, LSTM, CNN, Transformer) able to receive the time series the data you generated in the previous exercise."
      ],
      "metadata": {
        "id": "zGXDiQQEZ5vL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (response to exercise 4)"
      ],
      "metadata": {
        "id": "8AhYwVhNfWGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 5:\n",
        "\n",
        "Train your model following two approaches:\n",
        "1. **Centralized model training:** Mix data from multiple APs to train the model in a centralized fashion.\n",
        "2. **Federated model training:** Consider APs as independent clients who contribute to training a global model by submitting local model updates.\n",
        "\n",
        "Show the results by calculating the following metrics from the de-normalized data:\n",
        "* Mean squared error (MSE)\n",
        "* Mean absolute error (MAE)\n",
        "* Mean absolute percentage error (MAPE)"
      ],
      "metadata": {
        "id": "Uy_SulYKeEn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (response to exercise 5)"
      ],
      "metadata": {
        "id": "TB4TAqiAeNXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 6 (EXTRA):\n",
        "\n",
        "Reconsider your design to improve the accuracy of your model. For that, you can find a better approach to split the data (e.g., using larger observation windows) and include additional features."
      ],
      "metadata": {
        "id": "LafMStmKfW4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (response to exercise 6)"
      ],
      "metadata": {
        "id": "2Eb3K84dgTb1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}